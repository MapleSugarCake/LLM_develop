import os
import time
import logging
import requests
import jieba
import concurrent.futures
from typing import List, Dict
from pathlib import Path
import functools

# ================= é…ç½®åŒºåŸŸ =================
# ä½¿ç”¨ Chat Completion API ç«¯ç‚¹
OLLAMA_API_URL = "http://open-webui-ollama.open-webui:11434/api/chat"
MODEL_NAME = "qwen3-coder:30b"


# Chunking (åˆ†æ®µç­–ç•¥) é…ç½®
# MAX_CTX = 32000
# ä¸ºæ¨¡å‹è¾“å‡ºé¢„ç•™çº¦ 12000 Tokenï¼Œå•æ¬¡åˆ‡ç‰‡æœ€å¤§ä¸Šé™ä¸º 20000 Token
CHUNK_MAX_TOKENS = 4000
CHUNK_OVERLAP = 400

# ç¦ç”¨ jieba çš„é»˜è®¤æ—¥å¿—è¾“å‡ºï¼Œä¿æŒ CLI æ¸…æ´
jieba.setLogLevel(logging.INFO)

# åˆå§‹åŒ–æŠ¥å‘Šå­˜å‚¨ç›®å½•
BASE_DIR = Path("./reports")
BASE_DIR.mkdir(parents=True, exist_ok=True)

#è°ƒè¯•ä»£ç 
def timetest(func):
    @functools.wraps(func)
    def wrapper(*args, **kwargs):
        start = time.time()
        result = func(*args, **kwargs)
        end = time.time()
        print(f"å‡½æ•°'{func.__name__}'è€—æ—¶ï¼š"+str(end-start))
        return result
    return wrapper

# ================= API äº¤äº’ä¸å¼‚å¸¸å¤„ç† =================
@timetest
def call_ollama_chat(system_prompt: str, user_prompt: str, retries: int = 3, timeout:int =600) -> str:
    """
    è°ƒç”¨ Ollama Chat Completion API [è¶…æ—¶æ§åˆ¶ã€ç½‘ç»œæ³¢åŠ¨é‡è¯•ä¸é¢‘ç‡é™åˆ¶å¤„ç†]
    """
    payload = {
        "model": MODEL_NAME,
        "messages": [
            {"role": "system", "content": system_prompt},
            {"role": "user", "content": user_prompt}
        ],
        "stream": False
    }
    print("\n"+str(payload))
    backoff = 2  # åˆå§‹é€€é¿æ—¶é—´
    print("çº¿ç¨‹å¼€å§‹å¤„ç†")

    for attempt in range(retries):
        try:
            # å¤§æ¨¡å‹å¤„ç†é•¿æ–‡æœ¬è€—æ—¶è¾ƒé•¿ï¼ŒTimeout è®¾ç½®ä¸º 600 ç§’
            response = requests.post(OLLAMA_API_URL, json=payload, timeout=timeout)

            # é¢‘ç‡é™åˆ¶ (Rate Limiting)
            if response.status_code == 429:
                print(f"  [è­¦å‘Š] è§¦å‘ API é¢‘ç‡é™åˆ¶ (429)ï¼Œ{backoff}ç§’åé‡è¯•...")
                time.sleep(backoff)
                backoff *= 2
                continue

            response.raise_for_status()
            data = response.json()

            # è§£æ Chat Completion çš„è¿”å›æ ¼å¼
            print(f"\nã€Šã€Šã€Šdataã€‹ã€‹ã€‹:\n{data}")
            return data.get('message', {}).get('content', '').strip()

        except requests.exceptions.Timeout:
            print(f"  [é”™è¯¯] API è¯·æ±‚è¶…æ—¶ (Timeout)ã€‚å°è¯• {attempt + 1}/{retries}...")
        except requests.exceptions.ConnectionError:
            print(f"  [é”™è¯¯] ç½‘ç»œè¿æ¥å¤±è´¥ï¼Œè¯·æ£€æŸ¥ Ollama æœåŠ¡ã€‚å°è¯• {attempt + 1}/{retries}...")
        except requests.exceptions.RequestException as e:
            print(f"  [é”™è¯¯] API è°ƒç”¨å¼‚å¸¸: {e}ã€‚å°è¯• {attempt + 1}/{retries}...")

        time.sleep(backoff)
        backoff *= 2

    return "ã€API è¯·æ±‚å¤±è´¥ï¼Œæ— æ³•ç”Ÿæˆç»“æœã€‚ã€‘"


# ================= ä¸Šä¸‹æ–‡è¶…é•¿åˆ‡ç‰‡ç®¡ç† =================
@timetest
def chunk_text(text: str) -> List[str]:
    """
    åˆ†æ®µæ»šåŠ¨å¤„ç† (Chunking & Sliding Window):
    åˆ©ç”¨ jieba åˆ†è¯ä¼°ç®— Token æ•°ï¼Œè¶…è¿‡é™åˆ¶åˆ™è¿›è¡Œå¸¦é‡å ç‰‡æ®µçš„åˆ‡åˆ†ã€‚
    """
    # è¯æ³•åˆ‡åˆ†ä¼°ç®— Token
    words = list(jieba.cut(text))
    total_tokens = len(words)

    if total_tokens <= CHUNK_MAX_TOKENS:
        return [text]

    print(f"  [ä¿¡æ¯] æ–‡æœ¬æ€» token ä¼°ç®—ä¸º {total_tokens}ï¼Œè¶…å‡ºå•æ¬¡å¤„ç†é™åˆ¶ï¼Œå¯åŠ¨åˆ†æ®µæ»šåŠ¨å¤„ç†ç­–ç•¥...")
    chunks = []
    start = 0
    while start < total_tokens:
        end = min(start + CHUNK_MAX_TOKENS, total_tokens)
        chunk = "".join(words[start:end])
        chunks.append(chunk)
        if end == total_tokens:
            break
        # æ»‘åŠ¨çª—å£ï¼šå‘åé€€å› overlap é•¿åº¦ï¼Œä¿è¯æ®µè½ä¸Šä¸‹æ–‡è¿è´¯æ€§
        start += (CHUNK_MAX_TOKENS - CHUNK_OVERLAP)

    return chunks


# ================= æ ¸å¿ƒåˆ†æé€»è¾‘ =================
@timetest
def extract_features(text: str) -> Dict[str, str]:
    """å¤šçº¿ç¨‹å¯¹å•ä¸€ç‰‡æ®µå¹¶å‘æå–ä¸‰å¤§åŸºç¡€ç‰¹å¾"""
    sys_prompt = "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„æ•°æ®å¤„ç†ä¸æ–‡æœ¬æ™ºèƒ½åˆ†æä¸“å®¶ã€‚"

    p_summary = f"è¯·å¯¹ä»¥ä¸‹æ–‡æœ¬è¿›è¡Œç»“æ„åŒ–çš„æ ¸å¿ƒæ‘˜è¦æå–ï¼Œè¯­è¨€éœ€ç²¾ç‚¼ï¼Œåªè¾“å‡ºæ‘˜è¦ï¼Œä¸è¦è¾“å‡ºåŸæ–‡ï¼š{text}"
    p_sentiment = f"è¯·åˆ†æä»¥ä¸‹æ–‡æœ¬çš„æƒ…æ„Ÿå€¾å‘ï¼ˆæ­£é¢/è´Ÿé¢/ä¸­æ€§ï¼‰ï¼Œå¹¶ç»™å‡ºç®€æ˜æ‰¼è¦çš„åˆ†æç†ç”±ï¼Œåªè¾“å‡ºæƒ…æ„Ÿå€¾å‘åŠç†ç”±ï¼Œä¸è¦è¾“å‡ºåŸæ–‡ï¼š{text}"
    p_keywords = f"è¯·æå–ä»¥ä¸‹æ–‡æœ¬ä¸­æœ€é‡è¦çš„ 5-10 ä¸ªå…³é”®è¯ï¼Œä½¿ç”¨é€—å·åˆ†éš”è¾“å‡ºï¼Œåªè¾“å‡ºå…³é”®è¯ï¼Œä¸è¦è¾“å‡ºåŸæ–‡ï¼š{text}"

    with concurrent.futures.ThreadPoolExecutor(max_workers=3) as executor:
        f_sum = executor.submit(call_ollama_chat, sys_prompt, p_summary)
        f_sen = executor.submit(call_ollama_chat, sys_prompt, p_sentiment)
        f_kwd = executor.submit(call_ollama_chat, sys_prompt, p_keywords)

        # è°ƒè¯•é€Ÿåº¦ä»£ç 
        task1ing = 0
        task2ing = 0
        task3ing = 0
        while (1):
            if task1ing == 0 :
                if f_sum.done():
                    print("å•ä¸€ç‰‡æ®µsummaryå®Œæˆ")
                    task1ing = 1
            if task2ing == 0:
                if f_sen.done():
                    print("å•ä¸€ç‰‡æ®µsensitiveå®Œæˆ")
                    task2ing = 1
            if task3ing == 0:
                if f_kwd.done():
                    print("å•ä¸€ç‰‡æ®µkeywordså®Œæˆ")
                    task3ing = 1
            if task1ing and task2ing and task3ing:
                break
        # è°ƒè¯•é€Ÿåº¦ä»£ç ç»“æŸ
        return {
            "summary": f_sum.result(),
            "sentiment": f_sen.result(),
            "keywords": f_kwd.result()
        }

@timetest
def process_single_document(text: str, index: int) -> Dict[str, str]:
    """
    å¤„ç†å•ä¸ªæ–‡æ¡£è¾“å…¥ï¼ˆé›†æˆè¶…é•¿æ–‡ Map-Reduce åˆå¹¶é€»è¾‘ï¼‰
    """
    print(f"[*] å¼€å§‹åˆ†ææ–‡æœ¬æ¡£ {index}...")
    chunks = chunk_text(text)

    # çŸ­æ–‡æœ¬ç›´æ¥å¤„ç†
    if len(chunks) == 1:
        res = extract_features(chunks[0])
        print(f"[+] æ–‡æœ¬æ¡£ {index} åˆ†æå®Œæˆã€‚")
        return res


    # é•¿æ–‡æœ¬ Map-Reduce å¤„ç†
    print(f"  [ä¿¡æ¯] æ–‡æœ¬æ¡£ {index} è¢«åˆ‡åˆ†ä¸º {len(chunks)} ä¸ªç‰‡æ®µï¼Œæ­£åœ¨å¹¶è¡Œå¤„ç†å„ç‰‡æ®µ...")
    chunk_results = []
    for i, chunk in enumerate(chunks):
        chunk_results.append(extract_features(chunk))

    print(f"  [ä¿¡æ¯] æ–‡æœ¬æ¡£ {index} å„ç‰‡æ®µå¤„ç†å®Œæ¯•ï¼Œå¯åŠ¨å…¨å±€ Reduce ç»“æœèšåˆ...")
    sys_prompt = "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„æ–‡æœ¬å¤„ç†ä¸“å®¶ï¼Œè´Ÿè´£èåˆå¹¶æ±‡æ€»å±€éƒ¨ä¿¡æ¯ã€‚"

    agg_sum = "ç»¼åˆä»¥ä¸‹å¤šä¸ªæ–‡æœ¬ç‰‡æ®µçš„æ‘˜è¦ï¼Œç”Ÿæˆä¸€ä¸ªè¿è´¯ä¸”å®Œæ•´çš„å…¨å±€æ€»æ‘˜è¦ï¼Œåªè¾“å‡ºå…¨å±€æ€»æ‘˜è¦ï¼š" + "\n---\n".join(
        [r["summary"] for r in chunk_results])
    agg_sen = "ç»¼åˆä»¥ä¸‹å¯¹åŒä¸€æ–‡ç« ä¸åŒæ®µè½çš„æƒ…æ„Ÿåˆ†æï¼Œç»™å‡ºä¸€ä¸ªæ•´ä½“çš„å…¨å±€æƒ…æ„Ÿå€¾å‘åŠæ€»ç»“ç†ç”±ï¼Œåªè¾“å‡ºå…¨å±€æƒ…æ„Ÿå€¾å‘å’Œç†ç”±ï¼š" + "\n---\n".join(
        [r["sentiment"] for r in chunk_results])
    agg_kwd = "ç»¼åˆä»¥ä¸‹å…³é”®è¯åˆ—è¡¨ï¼Œå»é‡å¹¶æå–å‡ºæœ€å…·ä»£è¡¨æ€§çš„ 10 ä¸ªæ ¸å¿ƒå…³é”®è¯ï¼ˆä»…ç”¨é€—å·åˆ†éš”ï¼‰ï¼Œåªè¾“å‡ºå…³é”®è¯ï¼š" + "\n---\n".join(
        [r["keywords"] for r in chunk_results])

    with concurrent.futures.ThreadPoolExecutor(max_workers=3) as executor:
        f_sum = executor.submit(call_ollama_chat, sys_prompt, agg_sum)
        f_sen = executor.submit(call_ollama_chat, sys_prompt, agg_sen)
        f_kwd = executor.submit(call_ollama_chat, sys_prompt, agg_kwd)

        # è°ƒè¯•é€Ÿåº¦ä»£ç 
        task1ing = 0
        task2ing = 0
        task3ing = 0
        while (1):
            if task1ing == 0:
                if f_sum.done():
                    print("é•¿æ–‡æœ¬ Map-Reduce summaryå®Œæˆ")
                    task1ing = 1
            if task2ing == 0:
                if f_sen.done():
                    print("é•¿æ–‡æœ¬ Map-Reduce sensitiveå®Œæˆ")
                    task2ing = 1
            if task3ing == 0:
                if f_kwd.done():
                    print("é•¿æ–‡æœ¬ Map-Reduce keywordså®Œæˆ")
                    task3ing = 1
            if task1ing and task2ing and task3ing:
                break
        # è°ƒè¯•é€Ÿåº¦ä»£ç ç»“æŸ

        res = {
            "summary": f_sum.result(),
            "sentiment": f_sen.result(),
            "keywords": f_kwd.result()
        }
    print(f"[+] æ–‡æœ¬æ¡£ {index} åˆ†æ®µæ±‡æ€»åˆ†æå®Œæˆã€‚")
    return res

@timetest
def generate_comparison(results: List[Dict[str, str]]) -> str:
    """å¤šæ–‡æ¡£å¯¹æ¯”åˆ†æ"""
    print("[*] æ­£åœ¨æ‰§è¡Œå¤šæ–‡æœ¬äº¤å‰å¯¹æ¯”åˆ†æ...")
    sys_prompt = "ä½ æ˜¯ä¸€ä¸ªé¡¶çº§æ•°æ®åˆ†æä¸“å®¶ã€‚è¯·ç”ŸæˆåŒ…å«'æ ¸å¿ƒå·®å¼‚'ã€'ä¸»é¢˜å…±æ€§'ä»¥åŠ'ç»¼åˆæ€»ç»“'ä¸‰ä¸ªæ¨¡å—çš„ç»“æ„åŒ–å¯¹æ¯” Markdown æŠ¥å‘Šã€‚"

    user_prompt = "ä»¥ä¸‹æ˜¯å¯¹å¤šä¸ªç‹¬ç«‹æ–‡æœ¬çš„åˆ†æç»“æœï¼Œè¯·è‡ªåŠ¨æ±‡æ€»è¿™äº›æ–‡æœ¬çš„å·®å¼‚ä¸å…±æ€§ï¼Œç”Ÿæˆå¯¹æ¯”æŠ¥å‘Šï¼š\n"
    for i, r in enumerate(results):
        user_prompt += f"### æ–‡æœ¬ {i + 1} åˆ†æ\n- **æ‘˜è¦**: {r['summary']}\n- **æƒ…æ„Ÿ**: {r['sentiment']}\n- **å…³é”®è¯**: {r['keywords']}\n\n"

    return call_ollama_chat(sys_prompt, user_prompt,3,600)


# ================= è¾“å…¥è¿‡æ»¤ä¸æ¸…ç† =================
def sanitize_input(text: str) -> str:
    """è¿‡æ»¤æ§åˆ¶å­—ç¬¦å’Œéæ³•è¾“å…¥"""
    if not text:
        return ""
    # ç®€å•çš„éæ³•å­—ç¬¦è¿‡æ»¤ï¼ˆå»é™¤æ— æ³•æ‰“å°çš„æ§åˆ¶å­—ç¬¦ï¼Œä¿ç•™æ¢è¡Œï¼‰
    cleaned = "".join(ch for ch in text if ch.isprintable() or ch in ['\n', '\r', '\t'])
    return cleaned.strip()


# ================= ä¸šåŠ¡æµç®¡ç† =================
def create_report():
    print("\n" + "=" * 40)
    print("           [ æ–°å»ºæŠ¥å‘Š ]")
    print("=" * 40)

    report_name = input("è¯·è¾“å…¥æŠ¥å‘Šåç§°: ").strip()
    if not report_name:
        print("[æ‹¦æˆª] æŠ¥å‘Šåç§°ä¸èƒ½ä¸ºç©ºï¼")
        return
    report_dir = Path(f"./reports/{report_name}")
    report_dir.mkdir(parents=True, exist_ok=True)

    inputs = []
    print("\nè¯·æä¾›è¦åˆ†æçš„èµ„æ–™å†…å®¹ï¼ˆå¯å¤šæ¬¡è¾“å…¥ï¼‰ã€‚å®Œæˆæ‰€æœ‰è¾“å…¥åï¼Œè¯·æŒ‰ '3' å¼€å§‹åˆ†æã€‚")
    while True:
        print("\né€‰æ‹©è¾“å…¥æº:  1. çº¯æ–‡æœ¬  |  2. æ–‡æœ¬æ–‡ä»¶è·¯å¾„  |  3. [ç»“æŸè¾“å…¥ï¼Œå¼€å§‹åˆ†æ]")
        choice = input("æ“ä½œ >> ").strip()

        if choice == '1':
            text = input("è¯·è¾“å…¥çº¯æ–‡æœ¬å†…å®¹: ")
            text = sanitize_input(text)
            if text:
                inputs.append(text)
                print(f"[æˆåŠŸ] å·²æ·»åŠ æ–‡æœ¬ã€‚å½“å‰å…± {len(inputs)} ä»½èµ„æ–™ã€‚")
            else:
                print("[æ‹¦æˆª] ç©ºè¾“å…¥æˆ–å…¨ä¸ºéæ³•å­—ç¬¦ï¼Œå·²å¿½ç•¥ã€‚")

        elif choice == '2':
            print("å½“å‰.è·¯å¾„ä¸ºï¼š "+str(Path.cwd()))
            path = input("è¯·è¾“å…¥çº¯æ–‡æœ¬æ–‡ä»¶è·¯å¾„ (å¦‚ ./data.txt): ").strip()
            if os.path.isfile(path):
                try:
                    with open(path, 'r', encoding='utf-8', errors='ignore') as f:
                        text = sanitize_input(f.read())
                        if text:
                            inputs.append(text)
                            print(f"[æˆåŠŸ] å·²è¯»å–æ–‡ä»¶å¹¶æ·»åŠ ã€‚å½“å‰å…± {len(inputs)} ä»½èµ„æ–™ã€‚")
                        else:
                            print("[æ‹¦æˆª] æ–‡ä»¶å†…å®¹ä¸ºç©ºï¼Œå·²å¿½ç•¥ã€‚")
                except Exception as e:
                    print(f"[é”™è¯¯] è¯»å–æ–‡ä»¶å¤±è´¥: {e}")
            else:
                print("[é”™è¯¯] è·¯å¾„æ— æ•ˆæˆ–æ–‡ä»¶ä¸å­˜åœ¨ã€‚")

        elif choice == '3':
            if not inputs:
                print("[é”™è¯¯] æ²¡æœ‰æœ‰æ•ˆçš„è¾“å…¥å†…å®¹ï¼Œæ— æ³•ç”ŸæˆæŠ¥å‘Šã€‚")
                return
            break
        else:
            print("[é”™è¯¯] æ— æ•ˆé€‰é¡¹ã€‚")

    print(f"\n[*] å¼€å§‹æµæ°´çº¿ä½œä¸šï¼Œå¤„ç† {len(inputs)} ä»½èµ„æ–™ (å¹¶å‘æ¨¡å¼)...")

    # å¹¶è¡Œå¤„ç†æ‰€æœ‰æ–‡æœ¬
    results = [None] * len(inputs)
    with concurrent.futures.ThreadPoolExecutor(max_workers=min(5, len(inputs))) as executor:
        future_to_idx = {
            executor.submit(process_single_document, text, i + 1): i for i, text in enumerate(inputs)
        }

        for future in concurrent.futures.as_completed(future_to_idx):
            idx = future_to_idx[future]
            try:
                results[idx] = future.result()
                md_line = [
                    f"###{report_name}çš„æ–‡æ¡£{idx + 1}æ™ºèƒ½åˆ†ææŠ¥å‘Š",
                    f"**ç”Ÿæˆæ—¶é—´**: {time.strftime('%Y-%m-%d %H:%M:%S')}",
                    "\n---"
                    f"\n## ğŸ“‘  æ–‡æœ¬æ‘˜è¦\n{results[idx]['summary']}",
                    f"\n## ğŸ­  æƒ…æ„Ÿå€¾å‘\n{results[idx]['sentiment']}",
                    f"\n## ğŸ”‘  æ ¸å¿ƒå…³é”®è¯\n{results[idx]['keywords']}",
                    "\n---"
                ]
                # ä¿å­˜å•ä¸ªç»“æœ
                single_report = "\n".join(md_line)

                file_path = report_dir / f"èµ„æ–™{idx+1}æŠ¥å‘Š.md"
                try:
                    with open(file_path, 'w', encoding='utf-8') as f:
                        f.write(single_report)
                    print(f"\n[âœ”ï¸ ] {idx+1}æŠ¥å‘Šç”ŸæˆæˆåŠŸï¼\nä¿å­˜ä½ç½®: {file_path.absolute()}")
                except Exception as e:
                    print(f"\n[âŒ ] ä¿å­˜{idx+1}æŠ¥å‘Šå¤±è´¥: {e}")

            except Exception as e:
                print(f"[è‡´å‘½å¼‚å¸¸] å¤„ç†æ–‡æœ¬æ¡£ {idx + 1} æ—¶å‡ºé”™: {e}")
                results[idx] = {"summary": "å¤„ç†å¤±è´¥", "sentiment": "å¤„ç†å¤±è´¥", "keywords": "å¤„ç†å¤±è´¥"}



    # å¦‚æœå…·æœ‰2ä¸ªåŠä»¥ä¸Šçš„ç‹¬ç«‹è¾“å…¥ï¼Œè§¦å‘å¯¹æ¯”åˆ†æè¿›é˜¶åŠŸèƒ½
    if len(inputs) >= 2:
        # æ„å»º Markdown
        md_lines = [
            f"# æ™ºèƒ½åˆ†ææŠ¥å‘Šï¼š{report_name}",
            f"**ç”Ÿæˆæ—¶é—´**: {time.strftime('%Y-%m-%d %H:%M:%S')}",
            "\n---"
        ]

        # åŸºç¡€åˆ†æåˆå¹¶
        for i, res in enumerate(results):
            md_lines.extend([
                f"\n## èµ„æ–™ {i + 1} åˆ†æç»“æœ",
                f"\n# ğŸ“‘  æ–‡æœ¬æ‘˜è¦\n{res['summary']}",
                f"\n# ğŸ­  æƒ…æ„Ÿå€¾å‘\n{res['sentiment']}",
                f"\n# ğŸ”‘  æ ¸å¿ƒå…³é”®è¯\n{res['keywords']}",
                "\n---"
            ])
        md_lines.append(f"\n## âš–ï¸ {report_name}å¤šèµ„æ–™æ·±åº¦å¯¹æ¯”åˆ†æ")
        comparison_res = generate_comparison(results)
        md_lines.append(comparison_res)

        summary_report = "\n".join(md_lines)

        # ä¿å­˜ç»“æœ
        files_path = report_dir / f"{report_name}æ±‡æ€»æŠ¥å‘Š.md"
        try:
            with open(files_path, 'w', encoding='utf-8') as f:
                f.write(summary_report)
            print(f"\n[âœ”ï¸ ] æ±‡æ€»æŠ¥å‘Šç”ŸæˆæˆåŠŸï¼\nä¿å­˜ä½ç½®: {files_path.absolute()}")
        except Exception as e:
            print(f"\n[âŒ ] ä¿å­˜æ±‡æ€»æŠ¥å‘Šå¤±è´¥: {e}")


def view_history():
    print("\n" + "=" * 40)
    print("           [ å†å²æŠ¥å‘Š ]")
    print("=" * 40)

    files = list(BASE_DIR.rglob("*.md"))
    if not files:
        print("ğŸ“ æš‚æ— ä»»ä½•å†å²æŠ¥å‘Šã€‚")
        return

    for i, f in enumerate(files):
        print(f" {i + 1}. {f.stem} (å¤§å°: {f.stat().st_size} å­—èŠ‚)")

    choice = input("\nè¯·è¾“å…¥è¦æŸ¥çœ‹çš„æŠ¥å‘Šç¼–å· (è¾“å…¥ 0 å–æ¶ˆ): ").strip()
    if choice.isdigit():
        idx = int(choice) - 1
        if 0 <= idx < len(files):
            try:
                with open(files[idx], 'r', encoding='utf-8') as f:
                    print("\n\n" + "â–¼" * 50)
                    print(f.read())
                    print("â–²" * 50 + "\n")
            except Exception as e:
                print(f"[é”™è¯¯] è¯»å–æ–‡ä»¶å¤±è´¥: {e}")
        elif choice != '0':
            print("[é”™è¯¯] ç¼–å·ä¸å­˜åœ¨ã€‚")
    else:
        print("[é”™è¯¯] è¾“å…¥æ— æ•ˆã€‚")


# ================= ç¨‹åºå…¥å£ =================
#ç®¡ç†æŠ¥å‘Šç•Œé¢
def main():
    while True:
        print("\n" + "#" * 45)
        print(" æ–‡æœ¬æ™ºèƒ½åˆ†æä¸æŠ¥å‘ŠåŠ©æ‰‹ (Ollama API ç‰ˆ)")
        print("#" * 45)
        print("  1. æ–°å»ºåˆ†ææŠ¥å‘Š")
        print("  2. æŸ¥çœ‹å†å²æŠ¥å‘Š")
        print("  3. é€€å‡ºç³»ç»Ÿ")
        print("-" * 45)

        choice = input("è¯·é€‰æ‹©æ‚¨çš„æ“ä½œ (1/2/3): ").strip()

        if choice == '1':
            create_report()
        elif choice == '2':
            view_history()
        elif choice == '3':
            print("æ„Ÿè°¢ä½¿ç”¨ï¼Œç³»ç»Ÿé€€å‡ºã€‚")
            break
        else:
            print("[æ‹¦æˆª] æ— æ•ˆè¾“å…¥ï¼Œè¯·é‡æ–°é€‰æ‹©ã€‚")


if __name__ == "__main__":
    main()